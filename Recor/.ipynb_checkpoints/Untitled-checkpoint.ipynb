{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa564807-5df1-4427-b1b8-d5517e020417",
   "metadata": {},
   "source": [
    "# -------------Experiment - 13-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c9bef-867c-4e8f-af28-c0652f9c2129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: click in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.19.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.3.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.11.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mehta\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install Python packages\n",
    "!pip install nltk spacy scikit-learn\n",
    "\n",
    "# Download the spaCy English model\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53cd88-8a7d-4551-bdb6-f3865db41100",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577d962-92a4-4fad-9828-f2d29979f765",
   "metadata": {},
   "source": [
    "# a) Tokenization removal of stop words,punchuation, POS & NER Tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de05ec-51ed-4147-bbe6-c3b6546edda5",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2622e-664d-418a-bef8-2f11b76a679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562d168-4b8d-454d-b250-dd3168966137",
   "metadata": {},
   "source": [
    "# Download required NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04771eb6-de4a-4e54-acb4-5ec960ef7009",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnltk\u001b[49m.download(\u001b[33m'\u001b[39m\u001b[33mpunkt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mstopwords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33maveraged_perceptron_tagger\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09840b9c-265e-4d0e-9a8f-9c2f88015329",
   "metadata": {},
   "source": [
    "# Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f499516f-31e0-4b6b-9b65-f85445a85206",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Apple is looking at buying U.K. startup for $1 billion. \n",
    "          Artificial Intelligence is the future of technology!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666b5da-3b99-4eb3-bde0-0cfc8f90a960",
   "metadata": {},
   "source": [
    "# Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909c5556-1b20-42e4-8d86-b24ca326ba07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokens = \u001b[43mword_tokenize\u001b[49m(text)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Tokens ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "\u001b[31mNameError\u001b[39m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"--- Tokens ---\")\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e20ae-a3ce-44ad-9289-73e37e0142a9",
   "metadata": {},
   "source": [
    "# Remove stop words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec37001-b8aa-4ecd-acd5-40a0e337c15d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stop_words = \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m.words(\u001b[33m'\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      2\u001b[39m punctuation_regex = re.compile(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mW_]+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# matches punctuation\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation_regex = re.compile(r'[\\W_]+') # matches punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63e9d1-686d-4f57-9ecb-39d305a8718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and\n",
    "print(\"\\n--- Tokens after Stopword & Punctuation Removal ---\")\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5cf24-7c05-4c62-a494-c38637e95fbf",
   "metadata": {},
   "source": [
    "# POS Tagging & NER using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e3989-0fe8-4f81-8414-cf4a0c78b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # Load small English model\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90501d45-2c8f-4fb2-8cb8-4f853488e9b7",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a208dfe-de0f-4c20-bccd-b71cb667ab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- POS Tagging ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- POS Tagging ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m:\n\u001b[32m      3\u001b[39m  \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken.text\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken.pos_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- POS Tagging ---\")\n",
    "for token in doc:\n",
    " print(f\"{token.text:<12} --> {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012ef2a-1112-41cb-a856-39876b7b26e9",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b6797d-1ed9-45aa-88d5-083c7db86064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Named Entities ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Named Entities ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m.ents:\n\u001b[32m      3\u001b[39m  \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ment.text\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<15\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ment.label_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Named Entities ---\")\n",
    "for ent in doc.ents:\n",
    " print(f\"{ent.text:<15} --> {ent.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd58a5c-fb04-453e-90d5-dad15e8f7711",
   "metadata": {},
   "source": [
    "# b. Bag of Words, TF-IDF Vectorisation & Ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd629ca7-0f7f-4137-99c9-09633471f4de",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7772a910-af1f-49ec-a343-4e601ca035eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vectorizer = \u001b[43mCountVectorizer\u001b[49m()\n\u001b[32m      2\u001b[39m bow = vectorizer.fit_transform([text])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Bag of Words ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform([text])\n",
    "print(\"\\n--- Bag of Words ---\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880513e7-9251-4407-bea8-efa763cb0e8b",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f895fa5-9ed8-4235-9efa-63bc3ff0fc3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tfidf_vectorizer = \u001b[43mTfidfVectorizer\u001b[49m()\n\u001b[32m      2\u001b[39m tfidf = tfidf_vectorizer.fit_transform([text])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- TF-IDF ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform([text])\n",
    "print(\"\\n--- TF-IDF ---\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "print(tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f493c-13bb-4e6e-96ac-afbc465cb36e",
   "metadata": {},
   "source": [
    "# N-grams (Bigrams and Trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095028f6-498d-4cf4-9da5-10438086250a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ngram_vectorizer = \u001b[43mCountVectorizer\u001b[49m(ngram_range=(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m      2\u001b[39m ngrams = ngram_vectorizer.fit_transform([text])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- N-grams (Bigrams and Trigrams) ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
    "ngrams = ngram_vectorizer.fit_transform([text])\n",
    "print(\"\\n--- N-grams (Bigrams and Trigrams) ---\")\n",
    "print(ngram_vectorizer.get_feature_names_out())\n",
    "print(ngrams.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b236a-1c2d-4460-86fa-9aa73ed1f7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
